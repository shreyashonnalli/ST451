{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5307747",
   "metadata": {},
   "source": [
    "# All imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a5e1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF, RationalQuadratic, WhiteKernel, ConstantKernel\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, balanced_accuracy_score, roc_curve, auc, precision_recall_curve, average_precision_score, roc_auc_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "import statsmodels.api as sm\n",
    "import scipy as sc\n",
    "from scipy.special import expit\n",
    "import sys\n",
    "from collections import Counter\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.4f}\".format(x)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31588a21",
   "metadata": {},
   "source": [
    "# Classification Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632ed6b3",
   "metadata": {},
   "source": [
    "## Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46f1c32",
   "metadata": {},
   "source": [
    "### Reading in Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36619b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('heart.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c51b44",
   "metadata": {},
   "source": [
    "### Dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd898e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1552c122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all numerical columns\n",
    "target_feature = [\"HeartDisease\"]\n",
    "numerical_covariates = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.drop([\"HeartDisease\", \"FastingBS\"])\n",
    "numerical_covariates_with_target = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.drop(\"FastingBS\")\n",
    "categorical_covariates = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "categorical_covariates.append(\"FastingBS\")\n",
    "\n",
    "print(\"Numerical Covariates:\", numerical_covariates.values)\n",
    "print(\"Categorical Covariates:\", categorical_covariates)\n",
    "print(\"Balance of target column:\", df[target_feature].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b527bbe0",
   "metadata": {},
   "source": [
    "We can see there are\n",
    "- 5 numerical covariates\n",
    "- 6 categorical covariates\n",
    "    - Sex: 2 categories\n",
    "    - ChestPainType: 4 categories\n",
    "    - RestingECG: 3 categories\n",
    "    - ExerciseAngina: 2 categories\n",
    "    - ST_Slope: 3 categories\n",
    "    - FastingBS: 2 categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01510fb1",
   "metadata": {},
   "source": [
    "#### Correlation matrix and scatter plot of all numerical features\n",
    "\n",
    "NOTE: We can see a lot of redundant samples with cholesterol being 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2048917f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "corr = df[numerical_covariates_with_target].corr()\n",
    "plt.figure()\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm',vmin=-1, vmax=1)\n",
    "plt.title('Correlation of numerical features')\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot\n",
    "pp = sns.pairplot(df[numerical_covariates_with_target], hue='HeartDisease')\n",
    "pp.fig.suptitle(\"Scatter plot of numerical features alongside Correlations\", y=1.02, fontsize=20)\n",
    "\n",
    "for ax in pp.axes.flatten():\n",
    "    if ax is not None:\n",
    "        ax.tick_params(axis='both', labelsize=10)  \n",
    "        ax.set_xlabel(ax.get_xlabel(), fontsize=20)\n",
    "        ax.set_ylabel(ax.get_ylabel(), fontsize=20)\n",
    "        \n",
    "\n",
    "pp._legend.set_bbox_to_anchor((1, 0.5))  \n",
    "pp._legend.set_title(\"Heart Disease\", prop={'size': 16})\n",
    "for text in pp._legend.texts:\n",
    "    text.set_fontsize(14)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65340c8",
   "metadata": {},
   "source": [
    "#### Categorical Variable Analysis - Proportion plots\n",
    "\n",
    "We first calculate the proportion of the target within each category of each categorical feature, and then plot the proportions within each category via a bar chart. This approach is better than comparing raw counts of the target variable within each category, because there may be imbalances of the counts of each covariate category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906c6649",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows, n_cols = 2, 3\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 10))\n",
    "axes = axes.flatten()  # Make it easy to index\n",
    "\n",
    "for idx, col in enumerate(categorical_covariates[:n_rows * n_cols]):\n",
    "    prop_df = (\n",
    "        df.groupby(col)[\"HeartDisease\"]\n",
    "        .value_counts(normalize=True)\n",
    "        .rename(\"proportion\")\n",
    "        .reset_index()\n",
    "    )\n",
    "    stacked_df = prop_df.pivot(index=col, columns=\"HeartDisease\", values=\"proportion\").fillna(0)\n",
    "\n",
    "    # Plot in corresponding axis\n",
    "    stacked_df.plot(kind=\"bar\", stacked=True, colormap=\"coolwarm\", ax=axes[idx], legend=False)\n",
    "    axes[idx].set_title(f\"Proportion of HeartDisease by {col}\")\n",
    "    axes[idx].set_xlabel(\"\")\n",
    "    axes[idx].set_ylabel(\"Proportion\")\n",
    "\n",
    "# Hide any unused subplots\n",
    "for ax in axes[len(categorical_covariates):]:\n",
    "    ax.set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab5b179",
   "metadata": {},
   "source": [
    "#### Finding erroneous rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db603352",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Looking for null values in each column:\")\n",
    "print((df.isnull().sum()))\n",
    "print(\"\\nLooking for 0 values in numerical columns:\")\n",
    "print((df[numerical_covariates]==0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09618ad9",
   "metadata": {},
   "source": [
    "## Data Splitting\n",
    "\n",
    "80% train, 10% validation, 10% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ef7d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['HeartDisease'])\n",
    "y = df['HeartDisease']\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.1, shuffle=True, random_state=1, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.1111111111, shuffle=True, random_state=1, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202c0f9d",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "We have clearly identified 1 source of incorrect data: numerical columns cholesterol and RestingBP equals 0. Looking at the pairplot and combining contextual knowledge, these values having 0 is clearly a fault in a data collection method, due to the following reasons:\n",
    "- Having a cholesterol of 0 is impossible, as all humans have some degree of cholesterol.\n",
    "- A resting blood pressure (systolic) of 0 mmHg would indicate no blood circulation â€” which is not compatible with life.\n",
    "\n",
    "NOTE: The variable OldPeak typically refers to ST depression caused by exercise. It's a measure taken during a stress test, such as a treadmill exercise. It represents the difference between ST segment height at rest and after exercise. OldPeak having value of 0 is NOT abnormal.\n",
    "- OldPeak = 0.0 means no ST Depression = normal response\n",
    "- OldPeak = 2.3 indicates significant Depression = possible heart disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e872883",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCleaner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, subset=None, keep='first'):\n",
    "        pass\n",
    "\n",
    "    def reset_indices(self, X_cleaned, y_cleaned):\n",
    "        return X_cleaned.reset_index(drop = True), y_cleaned.reset_index(drop = True)\n",
    "    \n",
    "    def remove_rows_with_0_column(self, X, y, col_name):\n",
    "        non_zero_mask = X[col_name] != 0\n",
    "        X_filtered = X[non_zero_mask]\n",
    "        y_filtered = y[non_zero_mask]\n",
    "        X_filtered, y_filtered = self.reset_indices(X_filtered, y_filtered)\n",
    "        return X_filtered, y_filtered\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y):\n",
    "        X_cleaned, y_cleaned = self.remove_rows_with_0_column(X, y, \"Cholesterol\")\n",
    "        X_cleaned, y_cleaned = self.remove_rows_with_0_column(X_cleaned, y_cleaned, \"RestingBP\")\n",
    "        return X_cleaned, y_cleaned\n",
    "\n",
    "binary_cats = [col for col in categorical_covariates if df[col].nunique() == 2]\n",
    "multi_cats = [col for col in categorical_covariates if df[col].nunique() > 2]\n",
    "\n",
    "# We drop the first column after doing one-hot encoding to avoid perfect collinearity among covariates\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('binary', OneHotEncoder(drop='first', sparse_output=False), binary_cats),\n",
    "    ('multi', OneHotEncoder(drop='first', sparse_output=False), multi_cats),\n",
    "    ('num', RobustScaler(), numerical_covariates),\n",
    "], remainder='passthrough')\n",
    "\n",
    "full_pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ec6b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = DataCleaner()\n",
    "\n",
    "\n",
    "X_train_cleaned, y_train_cleaned = dc.transform(X = X_train, y = y_train)\n",
    "X_val_cleaned , y_val_cleaned = dc.transform(X = X_val, y = y_val)\n",
    "X_test_cleaned , y_test_cleaned = dc.transform(X = X_test, y = y_test)\n",
    "\n",
    "X_train_preprocessed = full_pipeline.fit_transform(X_train_cleaned, y_train_cleaned)\n",
    "X_val_preprocessed = full_pipeline.fit_transform(X_val_cleaned, y_val_cleaned)\n",
    "X_test_preprocessed = full_pipeline.fit_transform(X_test_cleaned, y_test_cleaned)\n",
    "\n",
    "print(\"Dataset size:\")\n",
    "print(len(X_train_preprocessed) + len(X_val_preprocessed) + len(X_test_preprocessed))\n",
    "print(\"\\nTraining:\")\n",
    "print(X_train_preprocessed.shape)\n",
    "print(y_train_cleaned.shape)\n",
    "print(\"\\nValidation\")\n",
    "print(X_val_preprocessed.shape)\n",
    "print(y_val_cleaned.shape)\n",
    "print(\"\\nTesting:\")\n",
    "print(X_test_preprocessed.shape)\n",
    "print(y_test_cleaned.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd2b331",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b12319a",
   "metadata": {},
   "source": [
    "### Model Selection Functions\n",
    "\n",
    "The following functions are explained below whenever they are utilized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e33a854",
   "metadata": {},
   "source": [
    "#### K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973f39b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct standard k-fold cross validation\n",
    "def k_fold_cross_validation(full_pipeline, X_train_cleaned, y_train_cleaned, scoring, model, n_splits=5):\n",
    "    X_train_preprocessed = full_pipeline.fit_transform(X_train_cleaned, y_train_cleaned)\n",
    "    cv = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(model, X_train_preprocessed, y_train_cleaned, cv = cv, scoring=scoring)\n",
    "    return scores\n",
    "\n",
    "# Conduct k-fold cross validation of a model with parameters using only statistically significant covariates    \n",
    "def k_fold_cross_validation_most_significant_covariates(full_pipeline, X_train_cleaned, y_train_cleaned, scoring, model, n_splits=5, k=4):\n",
    "    def get_covariates_appearing_atleast_k_times(significant_covs_in_splits, k = n_splits-1):\n",
    "        if k > n_splits: return\n",
    "        counter = Counter()\n",
    "        for arr in significant_covs_in_splits:\n",
    "            counter.update(arr)\n",
    "            \n",
    "        covariates_at_least_k = sorted([item for item, count in counter.items() if count >= k])\n",
    "        covariates_at_least_k = np.array(covariates_at_least_k)\n",
    "        return covariates_at_least_k\n",
    "    \n",
    "    X_train_preprocessed = full_pipeline.fit_transform(X_train_cleaned, y_train_cleaned)\n",
    "    cv = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "    significant_covs = []\n",
    "\n",
    "    for train_idx, val_idx in cv.split(X_train_preprocessed):\n",
    "        X_train_fold, X_val_fold = X_train_preprocessed[train_idx, :], X_train_preprocessed[val_idx, :]\n",
    "        y_train_fold, y_val_fold = y_train_cleaned[train_idx], y_train_cleaned[val_idx]\n",
    "        \n",
    "        X_train_fold = sm.add_constant(X_train_fold)\n",
    "        X_val_fold = sm.add_constant(X_val_fold)\n",
    "        \n",
    "        model = sm.Logit(y_train_fold, X_train_fold)\n",
    "        result = model.fit(disp=0)\n",
    "        \n",
    "        significant_features = np.where(result.pvalues <= 0.05)[0]\n",
    "        \n",
    "        X_train_fold_selected = X_train_fold[:, significant_features]\n",
    "        X_val_fold_selected = X_val_fold[:, significant_features]\n",
    "        \n",
    "        model_selected = sm.Logit(y_train_fold, X_train_fold_selected)\n",
    "        result_selected = model_selected.fit(disp=0)\n",
    "        \n",
    "        y_pred_val = result_selected.predict(X_val_fold_selected)\n",
    "        \n",
    "        if scoring == 'roc_auc':\n",
    "            score = roc_auc_score(y_val_fold, y_pred_val)\n",
    "        \n",
    "        scores.append(score)\n",
    "        significant_covs.append(significant_features)\n",
    "        \n",
    "    significant_covs = get_covariates_appearing_atleast_k_times(significant_covs, k=k)\n",
    "    return scores, significant_covs\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6f28d4",
   "metadata": {},
   "source": [
    "#### Bayesian Model Evidence Based Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22843550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evidence based selection for Bayesian Logistic Regression\n",
    "def bayesian_model_evidence_selection(full_pipeline, X_train_cleaned, y_train_cleaned, BayesianLogisticRegressionClass, num_models = 10, seed = 1):\n",
    "    np.random.seed(seed)\n",
    "    X_train_preprocessed = full_pipeline.fit_transform(X_train_cleaned, y_train_cleaned)\n",
    "    param_indices = list(range(X_train_preprocessed.shape[1]))\n",
    "    \n",
    "    all_subsets = []\n",
    "    all_evidences = []\n",
    "    best_subset = []\n",
    "    highest_evidence = -sys.maxsize - 1\n",
    "    \n",
    "    for i in range(num_models):\n",
    "        subset_size = np.random.randint(1, len(param_indices))\n",
    "        \n",
    "        if i == 0:\n",
    "            subset = list(range(X_train_preprocessed.shape[1]))\n",
    "        else:\n",
    "            subset = np.random.choice(param_indices, subset_size, replace=False)\n",
    "        subset = sorted(subset)\n",
    "        \n",
    "        blr = BayesianLogisticRegressionClass(\n",
    "                                beta_0 = np.zeros(len(subset) + 1),\n",
    "                                m_0 = np.zeros(len(subset) + 1),\n",
    "                                sigma_0_inv= (X_train_preprocessed[:, subset].T @ X_train_preprocessed[:, subset])/ X_train_preprocessed.shape[0],\n",
    "                                maxiter=100,\n",
    "                                tolerance=1e-05,\n",
    "                                fit_intercept=True,\n",
    "                                unit_information_prior=True,\n",
    "                                verbose = 0\n",
    "                                )\n",
    "        \n",
    "        blr.fit(X_train_preprocessed[:, subset], y_train_cleaned[:])\n",
    "        \n",
    "        if blr.log_model_evidence > highest_evidence:\n",
    "            highest_evidence = blr.log_model_evidence\n",
    "            best_subset = subset\n",
    "\n",
    "        all_subsets.append(subset)\n",
    "        all_evidences.append(blr.log_model_evidence)\n",
    "        \n",
    "        print(\"Finished calculating evidence for subset number:\", i+1)\n",
    "    \n",
    "    return highest_evidence, best_subset, all_evidences, all_subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d24e825",
   "metadata": {},
   "source": [
    "### Model Evaluation Class\n",
    "\n",
    "This class is used to evaluate performance on a particular dataset, and takes in a fitted model. For example, evaluating performance on validation or test set and takes in fitted model on training set. It calculates all sorts of classification metrics and curves, comprehensively evaluating performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98ffb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes evaluating a fitted classifier using all different metrics and curves\n",
    "class ClassificationEvaluator(ABC):\n",
    "    def __init__(self, model, X_evaluation_preprocessed, y_evaluation_cleaned, feature_names):\n",
    "        self.model = model\n",
    "        self.feature_names = feature_names\n",
    "        self.real = y_evaluation_cleaned \n",
    "        self.preds = self.model.predict(X_evaluation_preprocessed[:, :])\n",
    "        self.pred_probabilities = self.model.predict_proba(X_evaluation_preprocessed[:, :])\n",
    "    \n",
    "    @abstractmethod\n",
    "    def plot_coefficients(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_coefficient_statistics(self):\n",
    "        pass\n",
    "\n",
    "    # Raw Accuracy, Balanced Accuracy, Sensitivity, Specificity, Precision, False Alarm Rate, F-Score\n",
    "    def get_metrics(self):\n",
    "        accuracy = accuracy_score(self.real, self.preds)\n",
    "        precision = precision_score(self.real, self.preds)\n",
    "        recall = recall_score(self.real, self.preds)\n",
    "        \n",
    "        tn, fp, fn, tp = confusion_matrix(self.real, self.preds).ravel()\n",
    "        specificity = tn / (tn + fp)\n",
    "        false_alarm_rate = fp / (tn + fp)\n",
    "        f1 = f1_score(self.real, self.preds)\n",
    "        balanced_accuracy = balanced_accuracy_score(self.real, self.preds)\n",
    "        \n",
    "        return {\n",
    "            'Accuracy': accuracy,\n",
    "            'Balanced accuracy': balanced_accuracy,\n",
    "            'Precision': precision,\n",
    "            'Sensivity/Recall': recall,\n",
    "            'Specificity': specificity,\n",
    "            'False Alarm Rate': false_alarm_rate,\n",
    "            'F1 Score': f1\n",
    "            }\n",
    "        \n",
    "    def plot_confusion_matrix(self):\n",
    "        cm = confusion_matrix(self.real, self.preds)\n",
    "        sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', cbar=False, \n",
    "                    xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted Label\")\n",
    "        plt.ylabel(\"True Label\")\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_roc_curve(self):\n",
    "        y_preds_label1_probability = self.pred_probabilities[:, 1]\n",
    "        fpr, tpr, thresholds = roc_curve(self.real, y_preds_label1_probability)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # Random classifier diagonal line\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate (1-specificity)')\n",
    "        plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "        plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_pr_curve(self):\n",
    "        y_preds_label1_probability = self.pred_probabilities[:, 1]\n",
    "        precision, recall, thresholds = precision_recall_curve(self.real, y_preds_label1_probability)\n",
    "        ap_score = average_precision_score(self.real, y_preds_label1_probability)\n",
    "\n",
    "        plt.plot(recall, precision, label=f'PR Curve (AP = {ap_score:.2f})', color='green')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision-Recall Curve')\n",
    "        plt.legend(loc='lower left')\n",
    "        plt.show()\n",
    "\n",
    "    def get_all_classification_metrics(self):\n",
    "        metrics = self.get_metrics()\n",
    "        print(metrics)\n",
    "        self.plot_coefficients()\n",
    "        self.plot_confusion_matrix()\n",
    "        self.plot_roc_curve()\n",
    "        self.plot_pr_curve()\n",
    "        self.get_coefficient_statistics()\n",
    "        pass\n",
    "    \n",
    "class LogisticRegressionClassificationEvaluator(ClassificationEvaluator):\n",
    "    def __init__(self, model, x_evaluation_preprocessed, y_evaluation_cleaned, feature_names, stats_model):\n",
    "        self.stats_model = stats_model\n",
    "        super().__init__(model, x_evaluation_preprocessed, y_evaluation_cleaned, feature_names)\n",
    "    \n",
    "    def plot_coefficients(self): \n",
    "        coefficients = self.model.coef_[0]\n",
    "        plt.bar(range(len(self.feature_names)), np.abs(coefficients))\n",
    "        plt.xticks(range(len(self.feature_names)),self.feature_names[:len(self.feature_names)],rotation=-45)\n",
    "        plt.xlabel('Coefficient')\n",
    "        plt.ylabel('Absolute value - log scale')\n",
    "        plt.yscale('log')\n",
    "        plt.show()\n",
    "        \n",
    "    def get_coefficient_statistics(self):\n",
    "        results = self.stats_model.fit(method='ncg',maxiter=30000)\n",
    "        print(results.summary())\n",
    "        print()\n",
    "\n",
    "        \n",
    "class BayesianLogisticRegressionClassificationEvaluator(ClassificationEvaluator):\n",
    "    def __init__(self, model, X_evaluation_preprocessed, y_evaluation_cleaned, feature_names):\n",
    "        super().__init__(model, X_evaluation_preprocessed, y_evaluation_cleaned, feature_names)\n",
    "        \n",
    "    def plot_coefficients(self):\n",
    "        coefficients = self.model.coef_\n",
    "        self.feature_names = pd.Index(['intercept']).append(self.feature_names)\n",
    "        plt.bar(range(len(self.feature_names)), np.abs(coefficients))\n",
    "        plt.xticks(range(len(self.feature_names)),self.feature_names[:len(self.feature_names)],rotation=-45)\n",
    "        plt.xlabel('Coefficient')\n",
    "        plt.ylabel('Absolute value - log scale')\n",
    "        plt.yscale('log')\n",
    "        plt.show()\n",
    "        return \n",
    "\n",
    "    def get_coefficient_statistics(self):\n",
    "        pd.set_option('display.width', None)\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        print(self.model.get_summary().to_string())\n",
    "        print()\n",
    "    \n",
    "class GaussianProcessClassificationEvaluator(ClassificationEvaluator):\n",
    "    def __init__(self, model, x_evaluation_preprocessed, y_evaluation_cleaned, feature_names):\n",
    "        super().__init__(model, x_evaluation_preprocessed, y_evaluation_cleaned, feature_names)\n",
    "\n",
    "    def _plot_coefficient_plotter(self, importance):\n",
    "        plt.bar(range(len(self.feature_names)), np.abs(importance))\n",
    "        plt.xticks(range(len(self.feature_names)),self.feature_names[:len(self.feature_names)],rotation=-45)\n",
    "        plt.title(\"GP Feature Importance (1 / Length Scale)\")\n",
    "        plt.xlabel('Coefficient')\n",
    "        plt.ylabel('Feature Importance (log scale)')\n",
    "        plt.yscale('log')\n",
    "        plt.show()\n",
    "\n",
    "    def get_coefficient_statistics(self):\n",
    "        return super().get_coefficient_statistics()\n",
    "    \n",
    "    def plot_coefficients(self):\n",
    "        kernel_params = self.model.kernel_.get_params()\n",
    "        length_scale_params = []\n",
    "        for kp_key in kernel_params:\n",
    "            if kp_key.endswith(\"length_scale\"):\n",
    "                length_scale_params.append(kp_key)\n",
    "        \n",
    "        for i in range(len(length_scale_params)):\n",
    "            coefficients = kernel_params[length_scale_params[i]]\n",
    "            if isinstance(coefficients, np.float64):\n",
    "                print(\"Isotropic kernel with length_scale value:\", coefficients)\n",
    "                continue\n",
    "            importance = 1 / coefficients\n",
    "            self._plot_coefficient_plotter(importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dc061c",
   "metadata": {},
   "source": [
    "### Gaussian Process Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9695f881",
   "metadata": {},
   "source": [
    "#### Cross Validation to find best Gaussian Process Kernel\n",
    "\n",
    "Unlike regression, we don't need to do sub-sampling and can do traditional k-fold cross validation. This is because the dataset is much smaller in this case. The training dataset has only 448 samples. We conduct 5-fold cross validation. to compare 2 kernels - RBF and Rational Quadratic. We add a constant to this kernel controlling for scale, and also white noise allowing for erroneous measurements. We use ROC-AUC as the metric across the different folds. We take the model with the highest average ROC-AUC across the splits. We do this because of a slight imbalance in the target variable, with there being ~500 positive samples and ~400 negative samples. Using ROC-AUC as a metric allows us to account for both Sensitivity and Specificity and choose a model maximizing both. Note a lot more models were tested, but omitted and only most important kernels are shown."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00075062",
   "metadata": {},
   "source": [
    "##### Isotropic RBF kernel\n",
    "NOTE: Below cell took ~10 mins to run on Apple MacBook M1 Air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fb51c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores_gp_rbf_all_cols = k_fold_cross_validation(full_pipeline = full_pipeline, \n",
    "                                                X_train_cleaned=X_train_cleaned, \n",
    "                                                y_train_cleaned=y_train_cleaned, \n",
    "                                                scoring='roc_auc', \n",
    "                                                model = GaussianProcessClassifier(kernel = \n",
    "                                                                                  ConstantKernel(constant_value=1,\n",
    "                                                                                                constant_value_bounds=(1e-1, 1e+10)\n",
    "                                                                                                )\n",
    "                                                                                  * RBF(length_scale=1.0, \n",
    "                                                                                      length_scale_bounds=(1e-10, 100)\n",
    "                                                                                      )\n",
    "                                                                                  + WhiteKernel(noise_level=1 ** 2, \n",
    "                                                                                              noise_level_bounds=(1e-10, 1e+10)\n",
    "                                                                                              )\n",
    "                                                                                  ), \n",
    "                                                n_splits=5)\n",
    "print(cv_scores_gp_rbf_all_cols)\n",
    "print(np.mean(cv_scores_gp_rbf_all_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9dae49",
   "metadata": {},
   "source": [
    "##### Anisotropic RBF kernel\n",
    "NOTE: Below cell took ~25 mins to run on Apple MacBook M1 Air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94ac416",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores_gp_rbf_all_cols_aniso = k_fold_cross_validation(full_pipeline = full_pipeline, \n",
    "                                                X_train_cleaned=X_train_cleaned, \n",
    "                                                y_train_cleaned=y_train_cleaned, \n",
    "                                                scoring='roc_auc', \n",
    "                                                model = GaussianProcessClassifier(kernel = \n",
    "                                                                                  ConstantKernel(constant_value=1,\n",
    "                                                                                                constant_value_bounds=(1e-10, 1e+10)\n",
    "                                                                                                )\n",
    "                                                                                  * RBF(length_scale=[1.0] * X_train_preprocessed.shape[1], \n",
    "                                                                                      length_scale_bounds=(1e-10, 1e+10)\n",
    "                                                                                      )\n",
    "                                                                                  + WhiteKernel(noise_level=1 ** 2, \n",
    "                                                                                              noise_level_bounds=(1e-10, 1e+10)\n",
    "                                                                                              )\n",
    "                                                                                  ), \n",
    "                                                n_splits=5)\n",
    "print(cv_scores_gp_rbf_all_cols_aniso)\n",
    "print(np.mean(cv_scores_gp_rbf_all_cols_aniso))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a62a0b0",
   "metadata": {},
   "source": [
    "##### Isotropic RationalQuadratic Kernel\n",
    "NOTE: Below cell took ~25 mins to run on Apple MacBook M1 Air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8165f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores_gp_rq_all_cols = k_fold_cross_validation(full_pipeline = full_pipeline, \n",
    "                                                X_train_cleaned=X_train_cleaned, \n",
    "                                                y_train_cleaned=y_train_cleaned, \n",
    "                                                scoring='roc_auc', \n",
    "                                                model = GaussianProcessClassifier(kernel = \n",
    "                                                                                  ConstantKernel(constant_value=1,\n",
    "                                                                                                constant_value_bounds=(1e-10, 1e+10)\n",
    "                                                                                                )\n",
    "                                                                                  * RationalQuadratic(length_scale=1.0,\n",
    "                                                                                                      alpha=1.0,\n",
    "                                                                                                      alpha_bounds=(1e-10, 1e+10)\n",
    "                                                                                                      )\n",
    "                                                                                  + WhiteKernel(noise_level=1 ** 2, \n",
    "                                                                                              noise_level_bounds=(1e-10, 1e+10)\n",
    "                                                                                              )\n",
    "                                                                                  ), \n",
    "                                                n_splits=5)\n",
    "print(cv_scores_gp_rq_all_cols)\n",
    "print(np.mean(cv_scores_gp_rq_all_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17795585",
   "metadata": {},
   "source": [
    "#### Retraining on training set and seeing performance on Validation Set\n",
    "\n",
    "We take the best performing kernel across different splits, refit on the entire training dataset, and see performance on unseen validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd87b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = ConstantKernel(constant_value=1,constant_value_bounds=(1e-10, 1e+10))* RBF(length_scale=[1.0] * X_train_preprocessed.shape[1], length_scale_bounds=(1e-10, 1e+10))+ WhiteKernel(noise_level=1 ** 2, noise_level_bounds=(1e-10, 1e+10))\n",
    "gp = GaussianProcessClassifier(kernel = kernel)\n",
    "\n",
    "gp.fit(X_train_preprocessed, y_train_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d060c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_evaluator_gp = GaussianProcessClassificationEvaluator(model=gp,\n",
    "                                                                     x_evaluation_preprocessed=X_val_preprocessed,\n",
    "                                                                     y_evaluation_cleaned=y_val_cleaned,\n",
    "                                                                     feature_names=[f'x{j+1}' for j in range(X_val_preprocessed.shape[1])])\n",
    "\n",
    "classification_evaluator_gp.get_all_classification_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee38025",
   "metadata": {},
   "source": [
    "### Logistic Regression Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753ce5e0",
   "metadata": {},
   "source": [
    "#### Cross Validation\n",
    "We utilize cross validation to compare 2 models\n",
    "- One is using all covariates.\n",
    "- Second model utilizes only statistically significant covariates in each split.\n",
    "    - It returns scores and covariates which are statistically significant in at least $k$ of the n_splits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e084e89",
   "metadata": {},
   "source": [
    "##### Cross validation using all covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abc1303",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores_log_reg_all_cols = k_fold_cross_validation(full_pipeline, X_train_cleaned, y_train_cleaned, 'roc_auc', model = LogisticRegression(penalty=None, solver='newton-cg'), n_splits=10)\n",
    "print(\"Cross Validation scores (ROC_AUC):\", cv_scores_log_reg_all_cols)\n",
    "print(\"Mean of Cross Validation scores (ROC_AUC):\", np.mean(cv_scores_log_reg_all_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788ec055",
   "metadata": {},
   "source": [
    "##### Cross-Validation of only statistically significant covariates\n",
    "\n",
    "This corresponds to the second cross-validation function. The workflow is as follows:\n",
    "1. Take a single training fold and validation fold, and fit the a Logistic Regression model on the training fold using all covariates\n",
    "2. Look at the statistical significance of each of the covariates, and record only the significant covariates\n",
    "3. Refit the model on the training fold using **only** statistically significant covariates\n",
    "4. Use this model to predict on validation fold, and get ROC AUC metric\n",
    "5. Record the indices of the statistically significant covariates of this split.\n",
    "6. After getting all scores for all folds, return the set of covariates which were statistically significant in at least $k$ of the n_splits number of splits, where $1 < k < $ n_splits, and the corresponding metric scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8599ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores_log_reg_sig_covs, sig_covs = k_fold_cross_validation_most_significant_covariates(full_pipeline, X_train_cleaned, y_train_cleaned, 'roc_auc', model = LogisticRegression(penalty=None, solver='newton-cg'), n_splits=10, k=8)\n",
    "print(\"Cross Validation scores (ROC_AUC):\", cv_scores_log_reg_sig_covs)\n",
    "print(\"Mean of Cross Validation scores (ROC_AUC):\",np.mean(cv_scores_log_reg_sig_covs))\n",
    "print(\"Signficant covariate indices (including intercept): \", sig_covs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1beb95c6",
   "metadata": {},
   "source": [
    "#### Testing both models on Validation set\n",
    "We have seen the performance of both models via cross validation. The model using all covariates appears to do better than the model using only statistically significant covariates. We will now see performances on the validation set of both models, after retraining models on the entire training set. We have a list of covariates which have appeared to be statistically significant at least k times across n_splits number of cross validation splits. We will use these covariates only to train a logistic regression model utilizing only statistically significant covariates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763c3170",
   "metadata": {},
   "source": [
    "##### All covariates on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb1dd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(penalty=None, solver='newton-cg')\n",
    "log_reg.fit(X_train_preprocessed, y_train_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac80234",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_evaluator_log_reg = LogisticRegressionClassificationEvaluator(model=log_reg,\n",
    "                                                                     x_evaluation_preprocessed=X_val_preprocessed,\n",
    "                                                                     y_evaluation_cleaned=y_val_cleaned,\n",
    "                                                                     feature_names=[f'x{i}' for i in range(1, 16)],\n",
    "                                                                     stats_model=sm.Logit(y_train_cleaned, sm.add_constant(X_train_preprocessed[:, :])))\n",
    "                                                            \n",
    "classification_evaluator_log_reg.get_all_classification_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed17d753",
   "metadata": {},
   "source": [
    "##### Statistically significant covariates on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73f7012",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_sig_covs = LogisticRegression(penalty=None, solver='newton-cg')\n",
    "log_reg_sig_covs.fit(X_train_preprocessed[:, sig_covs-1], y_train_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08793d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_evaluator_log_reg_sig_covs = LogisticRegressionClassificationEvaluator(model=log_reg_sig_covs,\n",
    "                                                                     x_evaluation_preprocessed=X_val_preprocessed[:, sig_covs-1],\n",
    "                                                                     y_evaluation_cleaned=y_val_cleaned,\n",
    "                                                                     feature_names=sig_covs,\n",
    "                                                                     stats_model=sm.Logit(y_train_cleaned, sm.add_constant(X_train_preprocessed[:, sig_covs-1])))\n",
    "                                                            \n",
    "classification_evaluator_log_reg_sig_covs.get_all_classification_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420c9715",
   "metadata": {},
   "source": [
    "### Bayesian Logistic Regression Classification\n",
    "\n",
    "The following class implements Bayesian Logistic Regression using the Laplace approximation and exposes a class interface similar to sklearn's implementation of classifiers. It inherits from the base classifier class part of the sklearn package. It extends from that in the sense that after fitting, it is able to provide a pandas dataframe of the summary of the fitted model including coefficients and the 95% confidence interval for the parameter estimate. It also automatically calculates model evidence while fitting to data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42698e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianLogisticRegression(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, beta_0, m_0, sigma_0_inv, maxiter = 100, tolerance = 1e-05, fit_intercept = True, unit_information_prior = True, verbose = 1):\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.beta_0 = beta_0 # beta_0 is where to start the iterative update of the algorithm. This doesn't affect the prior, but is a numerical helper, NOT statistical assumption.\n",
    "        self.m_0 = m_0 # m_0 is the prior mean of the distribution over weights beta.\n",
    "        self.sigma_0_inv = sigma_0_inv # Prior precision matrix\n",
    "        self.maxiter = maxiter\n",
    "        self.tolerance = tolerance\n",
    "        self.unit_information_prior = unit_information_prior\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def __log_likelihood(self, X, y, beta):\n",
    "        log_likelihood = y.T @ np.log(expit(X @ beta)) + (1 - y).T @ np.log(1 - expit(X @ beta))\n",
    "        return log_likelihood\n",
    "\n",
    "    def __log_likelihood_derivative(self, X, y, beta):\n",
    "        log_likelihood_derivative =  X.T @ (expit(X @ beta) - y)\n",
    "        return log_likelihood_derivative\n",
    "\n",
    "    def __log_likelihood_second_derivative(self, X, y, beta):\n",
    "        S = np.diag(expit(X @ beta) * (1 - expit(X @ beta)))\n",
    "        Hessian = X.T @ S @ X\n",
    "        return Hessian\n",
    "    \n",
    "    def __log_posterior(self, X, y, beta):\n",
    "        log_likelihood = self.__log_likelihood(X, y, beta)\n",
    "        log_prior = - 0.5 * (beta - self.m_0).T @ self.sigma_0_inv @ (beta - self.m_0)\n",
    "        return log_likelihood + log_prior\n",
    "    \n",
    "    def __neg_log_posterior(self, X, y, beta):\n",
    "        log_posterior = self.__log_posterior(X, y, beta)\n",
    "        return -log_posterior\n",
    "    \n",
    "    def __log_posterior_derivative(self, X, y, beta):\n",
    "        log_posterior_derivative = X.T @ (y - expit(X @ beta)) + self.sigma_0_inv @ (beta - self.m_0)\n",
    "        return log_posterior_derivative\n",
    "    \n",
    "    def __neg_log_posterior_derivative(self, X, y, beta):\n",
    "        log_posterior_derivative = self.__log_posterior_derivative(X, y, beta)\n",
    "        return -log_posterior_derivative\n",
    "    \n",
    "    def __log_posterior_second_derivative(self, X, y, beta):\n",
    "        S = np.diag(expit(X @ beta) * (1 - expit(X @ beta)))\n",
    "        log_posterior_second_derivative = - (X.T @ S @ X) - self.sigma_0_inv\n",
    "        return log_posterior_second_derivative\n",
    "\n",
    "    def __neg_log_posterior_second_derivative(self, X, y, beta):\n",
    "        log_posterior_second_derivative = self.__log_posterior_second_derivative(X, y, beta)\n",
    "        return - log_posterior_second_derivative\n",
    "    \n",
    "    def __newton_raphson_optimization(self, X, y):\n",
    "        i = 0\n",
    "        beta = self.beta_0\n",
    "        neg_log_posterior = self.__neg_log_posterior(X, y, beta)\n",
    "        abs_diff = 1\n",
    "        while abs_diff > self.tolerance and i < self.maxiter:\n",
    "            if self.verbose == 1: print('iteration ',i+1,' Negative Log Posterior ',neg_log_posterior, ' AbDiff ', abs_diff)\n",
    "            neg_log_posterior_derivative = self.__neg_log_posterior_derivative(X, y, beta)\n",
    "            neg_log_posterior_hessian = self.__neg_log_posterior_second_derivative(X, y, beta)\n",
    "            neg_log_posterior_hessian_inverse = sc.linalg.inv(neg_log_posterior_hessian)\n",
    "            beta = beta - neg_log_posterior_hessian_inverse @ neg_log_posterior_derivative\n",
    "\n",
    "            neg_log_posterior_new = self.__neg_log_posterior(X, y, beta)\n",
    "            abs_diff = np.abs(neg_log_posterior_new - neg_log_posterior)\n",
    "            neg_log_posterior = neg_log_posterior_new\n",
    "            i += 1\n",
    "            \n",
    "        if (i == self.maxiter):\n",
    "            print('Did not Converge') \n",
    "        \n",
    "        return beta, neg_log_posterior_hessian_inverse, True\n",
    "    \n",
    "    def __calculate_model_evidence(self, X, y):\n",
    "        log_likelihood = self.__log_likelihood(X, y, self.beta_map)\n",
    "        log_prior = -0.5 * (self.beta_map - self.m_0).T @ self.sigma_0_inv @ (self.beta_map - self.m_0) \\\n",
    "            + 0.5 * np.linalg.slogdet(self.sigma_0_inv)[1] \\\n",
    "            - 0.5 * len(self.beta_map) * np.log(2 * np.pi)\n",
    "            \n",
    "        hessian = self.__neg_log_posterior_second_derivative(X, y, self.beta_map)\n",
    "        log_det_hessian = np.linalg.slogdet(hessian)[1]\n",
    "        normalization = 0.5 * (len(self.beta_map) * np.log(2*np.pi) - log_det_hessian)\n",
    "        log_evidence = log_likelihood + log_prior + normalization\n",
    "        return log_evidence\n",
    "    \n",
    "    def get_summary(self):\n",
    "        check_is_fitted(self)\n",
    "        se = np.sqrt(np.diag(self.sigma_map))\n",
    "        lower5 = self.beta_map - 1.96 * se\n",
    "        upper5 = self.beta_map + 1.96 * se\n",
    "        \n",
    "        results = np.column_stack([self.beta_map ,se ,lower5 ,upper5])\n",
    "        col = ['post mean','post se','lower 5% bound','upper 95% bound']\n",
    "        summary = pd.DataFrame(results, columns=col, index=[f'x{j+1}' for j in range(len(self.beta_map))])\n",
    "        return summary\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y)\n",
    "        if self.fit_intercept:\n",
    "            X = np.column_stack([np.ones(X.shape[0]), X])\n",
    "        if self.unit_information_prior:\n",
    "            self.sigma_0_inv = (X.T @ X) / X.shape[0]\n",
    "        \n",
    "        beta_map, sigma_map, converged = self.__newton_raphson_optimization(X, y)\n",
    "        if converged:\n",
    "            self.beta_map = beta_map\n",
    "            self.sigma_map = sigma_map\n",
    "            self.log_model_evidence = self.__calculate_model_evidence(X, y)\n",
    "            self.coef_ = beta_map\n",
    "            self.fitted_ = True\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X, n_samples = 10000):\n",
    "        check_is_fitted(self)\n",
    "        X = check_array(X)\n",
    "        if self.fit_intercept:\n",
    "            X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "            \n",
    "        beta_map_samples = np.random.multivariate_normal(self.beta_map, self.sigma_map, size=n_samples)\n",
    "        logits = X @ beta_map_samples.T\n",
    "        probabilities = expit(logits)\n",
    "        mean_probs = probabilities.mean(axis=1)\n",
    "        return np.vstack([1 - mean_probs, mean_probs]).T\n",
    "    \n",
    "    def predict(self, X, n_samples = 10000):\n",
    "        check_is_fitted(self)\n",
    "        proba = self.predict_proba(X, n_samples=n_samples)\n",
    "        return (proba[:, 1] >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0578eb04",
   "metadata": {},
   "source": [
    "#### Bayesian Model Evidence\n",
    "\n",
    "We utiise the above class's capabilities of calculating model evidence along with a function to automatically select the set of covariates which maximize the marginal log likelihood of the model i.e. the log evidence. The function randomly selects a set of covariates, and fits them on the training dataset. We then calculate the marginal log likelihood of the Laplace Approximation, and use the model maximizing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3be950",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_evidence, best_feature_subset, all_evidences, all_subsets = bayesian_model_evidence_selection(full_pipeline, \n",
    "                                                                            X_train_cleaned, \n",
    "                                                                            y_train_cleaned, \n",
    "                                                                            BayesianLogisticRegression,\n",
    "                                                                            num_models=10\n",
    "                                                                            )\n",
    "\n",
    "print(\"Best Model Evidence:\", best_evidence)\n",
    "print(\"Best Feature Subset:\", best_feature_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe74b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_evidences)\n",
    "print(all_subsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5a14e5",
   "metadata": {},
   "source": [
    "#### Refitting model with highest marginal likelihood on training set and evaluating performance on validation\n",
    "\n",
    "We use the model using only the covariates producing the highest marginal log likelihood. We see it's performance on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb083bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "blr = BayesianLogisticRegression(beta_0 = np.zeros(len(best_feature_subset) + 1),\n",
    "                                 m_0 = np.zeros(len(best_feature_subset) + 1),\n",
    "                                 sigma_0_inv= (X_train_preprocessed[:, best_feature_subset].T @ X_train_preprocessed[:, best_feature_subset])/ X_train_preprocessed.shape[0],\n",
    "                                 maxiter=100,\n",
    "                                 tolerance=1e-05,\n",
    "                                 fit_intercept=True,\n",
    "                                 verbose=0\n",
    "                                )\n",
    "\n",
    "blr.fit(X_train_preprocessed[:, best_feature_subset], y_train_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3e85c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_evaluator_blr = BayesianLogisticRegressionClassificationEvaluator(\n",
    "                                                                            model=blr,\n",
    "                                                                            X_evaluation_preprocessed=X_val_preprocessed[:, best_feature_subset],\n",
    "                                                                            y_evaluation_cleaned=y_val_cleaned,\n",
    "                                                                            feature_names=pd.Index([f'x{i}' for i in best_feature_subset]),\n",
    "                                                                        )\n",
    "\n",
    "classification_evaluator_blr.get_all_classification_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ac533a",
   "metadata": {},
   "source": [
    "## Final Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1ed3d1",
   "metadata": {},
   "source": [
    "The best model we found was the Bayesian Logistic Regression classifier with the feature subset having the highest marginal likelihood. The validation set ROC AUC was 0.94, and the area under Precision-Recall curve was also 0.94. This model also had an F1-score of 0.87, which was higher than the ones produced by Logistic Regression and Gaussian Process Classifier which were ~0.80 and ~0.85 respectively. The Bayesian Logistic Regression model has beaten other models on most of the classification metrics, and we can see this visually via the confusion matrix.\n",
    "\n",
    "We now evaluate the same performance on the final unseen test set, which is unseen from the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c079807",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_evaluator_blr = BayesianLogisticRegressionClassificationEvaluator(\n",
    "                                                                            model=blr,\n",
    "                                                                            X_evaluation_preprocessed=X_test_preprocessed[:, best_feature_subset],\n",
    "                                                                            y_evaluation_cleaned=y_test_cleaned,\n",
    "                                                                            feature_names=pd.Index([f'x{i}' for i in best_feature_subset]),\n",
    "                                                                        )\n",
    "\n",
    "classification_evaluator_blr.get_all_classification_metrics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor \n",
    "from sklearn.gaussian_process.kernels import RBF, RationalQuadratic, WhiteKernel, ConstantKernel\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import OrdinalEncoder, RobustScaler\n",
    "from sklearn.metrics import pairwise_distances_argmin_min, mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "import statsmodels.api as sm\n",
    "import scipy as sc\n",
    "from scipy.stats import multivariate_t, t, multivariate_normal\n",
    "from scipy.special import loggamma\n",
    "import sys\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.4f}\".format(x)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression problem\n",
    "\n",
    "We will use the diamonds dataset to explore Bayesian methods for regression, namely Gaussian Processes Regression, and Bayesian Linear Regression. We will aim to predict the prices of diamonds using the provided features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('diamonds.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plotter():\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        pass\n",
    "    \n",
    "    def plot(self, x, y, plt_type):\n",
    "        if plt_type == 'scatter':\n",
    "            plt.scatter(self.data[x], self.data[y])\n",
    "            plt.title(f\"{x} against {y}\")\n",
    "        if plt_type == 'box':\n",
    "            sns.boxplot(data=self.data, x=x, y=y)\n",
    "            plt.title(f\"{x} against {y}\")\n",
    "        if plt_type == 'hist':\n",
    "            sns.histplot(self.data[x], bins = 40, kde=False, edgecolor='black')\n",
    "            plt.title(f\"{x} Histogram\")\n",
    "            plt.ylabel('Frequency')\n",
    "        plt.show()\n",
    " \n",
    "pltr = Plotter(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram plots of numerical features\n",
    "\n",
    "We plot histograms to see which type of scaler would be appropriate while fitting models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltr.plot('depth', None, 'hist')\n",
    "pltr.plot('table', None, 'hist')\n",
    "pltr.plot('carat', None, 'hist')\n",
    "pltr.plot('price', None, 'hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Matrix of numerical features\n",
    "\n",
    "We can see some highly correlated features including the group of z, x, y all being highly correlated with each other and with the carat covariate. We will remove these 3 covariates as a result of this, as it may inflate errors of regression coefficients, make them unstable, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.select_dtypes(include='number').corr()\n",
    "plt.figure() \n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation of numerical features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatter plot of low correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltr.plot('depth', 'price', 'scatter')\n",
    "pltr.plot('table', 'price', 'scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatter plot of highly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltr.plot('carat', 'x', 'scatter')\n",
    "pltr.plot('x', 'y', 'scatter')\n",
    "pltr.plot('y', 'z', 'scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical/Ordinal feature analysis\n",
    "Box and Whisker plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(5 * 3, 4 * 1))\n",
    "axes = axes.flatten()\n",
    "\n",
    "sns.boxplot(data=df, x='color', y='price', ax=axes[0], order=['J', 'I', 'H', 'G', 'F', 'E', 'D'])\n",
    "axes[0].set_title(f'Boxplot of color against price')\n",
    "axes[0].set_xlabel('Color')\n",
    "axes[0].set_ylabel('Price')\n",
    "\n",
    "sns.boxplot(data=df, x='cut', y='price', ax=axes[1], order=['Fair', 'Good', 'Very Good', 'Premium', 'Ideal'])\n",
    "axes[1].set_title(f'Boxplot of cut against price')\n",
    "axes[1].set_xlabel('Cut')\n",
    "axes[1].set_ylabel('Price')\n",
    "\n",
    "sns.boxplot(data=df, x='clarity', y='price', ax=axes[2], order=['I1', 'SI2', 'SI1', 'VS2', 'VS1', 'VVS2', 'VVS1', 'IF'])\n",
    "axes[2].set_title(f'Boxplot of clarity against price')\n",
    "axes[2].set_xlabel('Clarity')\n",
    "axes[2].set_ylabel('Price')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Splitting\n",
    "\n",
    "We split the dataset before preprocessing so we prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['price'])\n",
    "y = df['price']\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, shuffle=True, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Classes\n",
    "\n",
    "The DataCleaner class is used to clean the dataset by getting rid of duplicate rows, erroneous rows such as if a particular dimension is zero, and to drop features which are deemed unnecessary i.e. x, y, z.\n",
    "\n",
    "Once cleaned, we can put the data through the preprocessing pipeline which encodes categorical variables and standardizes numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCleaner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, subset=None, keep='first'):\n",
    "        self.subset = subset\n",
    "        self.keep = keep\n",
    "        \n",
    "    def reset_indices(self, X_cleaned, y_cleaned):\n",
    "        return X_cleaned.reset_index(drop = True), y_cleaned.reset_index(drop = True)\n",
    "    \n",
    "    def get_list_of_similar_pairs(self, X):\n",
    "        distance_matrix = euclidean_distances(X[['x', 'y', 'z']])\n",
    "        threshold = 1e-3\n",
    "        near_duplicate_pairs = np.argwhere(distance_matrix < threshold)\n",
    "        filtered_pairs = [(i, j) for i, j in near_duplicate_pairs if i < j]\n",
    "        \n",
    "        rows_to_remove = set()\n",
    "        for i,j in filtered_pairs:\n",
    "            if i not in rows_to_remove and j not in rows_to_remove:\n",
    "                rows_to_remove.add(j)\n",
    "        \n",
    "        return rows_to_remove\n",
    "\n",
    "    def get_n_samples(self, X, n):\n",
    "        kmeans = KMeans(n_clusters=n, random_state=42)\n",
    "        kmeans.fit(X[['x', 'y', 'z', 'carat', 'depth', 'table']])\n",
    "        indices, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, X[['x', 'y', 'z', 'carat', 'depth', 'table']])\n",
    "        return indices\n",
    "        \n",
    "    def filter(self, X_cleaned, y_cleaned, n):\n",
    "        # Filter to get only 1500 data points as GP regression can't handle a lot of data\n",
    "        indices_to_keep = self.get_n_samples(X_cleaned, n)\n",
    "        X_cleaned = X_cleaned.iloc[indices_to_keep]\n",
    "        y_cleaned = y_cleaned.iloc[indices_to_keep]\n",
    "        X_cleaned, y_cleaned = self.reset_indices(X_cleaned, y_cleaned) \n",
    "        return X_cleaned, y_cleaned\n",
    "        \n",
    "    def remove_rows_with_faulty_diamond_size(self, X_cleaned, y_cleaned):\n",
    "        mask_nonzero = ~((X_cleaned['x'] == 0) | (X_cleaned['y'] == 0) | (X_cleaned['z'] == 0))\n",
    "        X_cleaned = X_cleaned[mask_nonzero]\n",
    "        y_cleaned = y_cleaned.loc[X_cleaned.index]\n",
    "        X_cleaned, y_cleaned = self.reset_indices(X_cleaned, y_cleaned) \n",
    "        return X_cleaned, y_cleaned\n",
    "    \n",
    "    def remove_duplicates(self, X, y):\n",
    "        X_cleaned = X.drop_duplicates(subset=self.subset, keep=self.keep)\n",
    "        y_cleaned = y.loc[X_cleaned.index]\n",
    "        X_cleaned, y_cleaned = self.reset_indices(X_cleaned, y_cleaned) \n",
    "        return X_cleaned, y_cleaned\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y, filt = False, cols_to_drop = []):\n",
    "        # Remove duplicate rows\n",
    "        X_cleaned, y_cleaned = self.remove_duplicates(X, y)\n",
    "\n",
    "        # Remove redundant data i.e. dimension of diamond is 0\n",
    "        X_cleaned, y_cleaned = self.remove_rows_with_faulty_diamond_size(X_cleaned, y_cleaned)\n",
    "\n",
    "        # Filter to get only 1500 items\n",
    "        if filt:\n",
    "            X_cleaned, y_cleaned = self.filter(X_cleaned, y_cleaned, 1500)\n",
    "        \n",
    "        # Drop certain features which are deemed unnecessary\n",
    "        if len(cols_to_drop) > 0:\n",
    "            X_cleaned = X_cleaned.drop(labels = cols_to_drop, axis = 1)\n",
    " \n",
    "        return X_cleaned, y_cleaned\n",
    "   \n",
    "    def fit_transform(self, X, y):\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X, y) \n",
    "\n",
    "\n",
    "ordinal_cols = ['cut', 'color', 'clarity']\n",
    "ordinal_categories = [\n",
    "    ['Fair', 'Good', 'Very Good', 'Premium', 'Ideal'],\n",
    "    ['J', 'I', 'H', 'G', 'F', 'E', 'D'],\n",
    "    ['I1', 'SI2', 'SI1', 'VS2', 'VS1', 'VVS2', 'VVS1', 'IF']\n",
    "]\n",
    "numeric_cols = ['carat', 'depth', 'table', 'x', 'y', 'z']\n",
    "numeric_cols = ['carat', 'depth', 'table']\n",
    "numeric_cols_standardize = ['depth', 'table']\n",
    "numeric_cols_normalize = ['carat']\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('ord', OrdinalEncoder(categories=ordinal_categories), ordinal_cols),\n",
    "    ('num', RobustScaler(), numeric_cols)\n",
    "], remainder='passthrough')\n",
    "\n",
    "\n",
    "full_pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning and Preprocessing the data\n",
    "\n",
    "- 60% Training\n",
    "- 20% Validation\n",
    "- 20% Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = DataCleaner()\n",
    "X_train_cleaned, y_train_cleaned = dc.transform(X = X_train, y = y_train, cols_to_drop=['x','y','z'])\n",
    "X_val_cleaned , y_val_cleaned = dc.transform(X = X_val, y = y_val, cols_to_drop=['x','y','z'])\n",
    "X_test_cleaned , y_test_cleaned = dc.transform(X = X_test, y = y_test, cols_to_drop=['x','y','z'])\n",
    "\n",
    "X_train_preprocessed = full_pipeline.fit_transform(X_train_cleaned, y_train_cleaned)\n",
    "X_val_preprocessed = full_pipeline.fit_transform(X_val_cleaned, y_val_cleaned)\n",
    "X_test_preprocessed = full_pipeline.fit_transform(X_test_cleaned, y_test_cleaned)\n",
    "\n",
    "print(\"Training:\")\n",
    "print(X_train_preprocessed.shape)\n",
    "print(y_train_cleaned.shape)\n",
    "print(\"\\nValidation\")\n",
    "print(X_val_preprocessed.shape)\n",
    "print(y_val_cleaned.shape)\n",
    "print(\"\\nTesting:\")\n",
    "print(X_test_preprocessed.shape)\n",
    "print(y_test_cleaned.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection functions\n",
    "\n",
    "The below functions are explained when they are used below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random subsampling cross validation for Gaussian Process Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_subsampling_split(X_train, y_train, tst_size = 2000, tr_size = 1500, seed = 1):\n",
    "    X_temp, X_cross_val, y_temp, y_cross_val = train_test_split(X_train, y_train, test_size=tst_size, shuffle=True, random_state=seed)\n",
    "    X_train_sub, _, y_train_sub, _ = train_test_split(X_temp, y_temp, train_size=tr_size, shuffle=True, random_state=seed)\n",
    "    return X_train_sub, X_cross_val, y_train_sub, y_cross_val\n",
    "\n",
    "'''\n",
    "Takes in:\n",
    "- X\n",
    "- y\n",
    "- full_pipeline\n",
    "- scoring\n",
    "\n",
    "Returns:\n",
    "- Array of scores from cross validation using random subsampling\n",
    "\n",
    "We use this for Gaussian Process Regression because it isn't possible for GP regression to be trained on all training samples due to computational complexity.\n",
    "We train on a subset of the training set of 1500 samples. We still evaluate on the same number of validation samples in cross validation to maintain comparability of the cv score with other models.\n",
    "'''\n",
    "def random_subsampling_cv(full_pipeline, X_train_cleaned, y_train_cleaned, scoring, model, train_size = 1500, numeric_cols_only = False, n_splits=10):\n",
    "    cv_scores = []\n",
    "    \n",
    "    X_train_preprocessed = full_pipeline.fit_transform(X_train_cleaned, y_train_cleaned)\n",
    "    \n",
    "    if numeric_cols_only:\n",
    "        X_train_preprocessed = X_train_preprocessed[:, -3:]\n",
    "    \n",
    "    for i in range(n_splits):\n",
    "        X_train_sub, X_val_sub, y_train_sub, y_val_sub = random_subsampling_split(\n",
    "                X_train_preprocessed, \n",
    "                y_train_cleaned, \n",
    "                tst_size=(len(X_train_preprocessed) // n_splits),\n",
    "                tr_size=train_size,\n",
    "                seed=i)\n",
    "\n",
    "        model.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "        y_pred_val_sub = model.predict(X_val_sub)\n",
    "        score = scoring(y_val_sub, y_pred_val_sub)\n",
    "        cv_scores.append(score)\n",
    "        print(\"Finished split:\", i+1)\n",
    "    \n",
    "    return cv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard k-fold cross validation\n",
    "def k_fold_cross_validation(full_pipeline, X_train_cleaned, y_train_cleaned, scoring, model, numeric_cols_only = False, n_splits=10):\n",
    "    X_train_preprocessed = full_pipeline.fit_transform(X_train_cleaned, y_train_cleaned)\n",
    "    if numeric_cols_only:\n",
    "        X_train_preprocessed = X_train_preprocessed[:, -3:]\n",
    "        \n",
    "    cv = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(model, X_train_preprocessed, y_train_cleaned, cv = cv, scoring=scoring)\n",
    "    return -scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian Model Evidence Based Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for bayesian linear regression to select covariate set with highest evidence.\n",
    "def bayesian_model_evidence_selection(full_pipeline, X_train_cleaned, y_train_cleaned, BayesianLinearRegressionClass, num_samples = 1000, num_models = 10, seed = 1):\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    X_train_preprocessed = full_pipeline.fit_transform(X_train_cleaned, y_train_cleaned)\n",
    "    \n",
    "    param_indices = np.array([0,1,2,3,4,5])\n",
    "    \n",
    "    all_subsets = []\n",
    "    all_evidences = []\n",
    "    best_subset = []\n",
    "    highest_evidence = -sys.maxsize - 1\n",
    "    \n",
    "    for i in range(num_models):\n",
    "        subset_size = np.random.randint(1, len(param_indices))\n",
    "        \n",
    "        if i == 0:\n",
    "            subset = [0,1,2,3,4,5]\n",
    "        else:\n",
    "            subset = np.random.choice(param_indices, subset_size, replace=False)\n",
    "        subset = sorted(subset)\n",
    "        \n",
    "        blr = BayesianLinearRegressionClass(\n",
    "                                mu_0=np.zeros(len(subset)+1),\n",
    "                                a_0=0.01,\n",
    "                                b_0=0.01,\n",
    "                                fit_intercept=True,\n",
    "                                unit_information_prior=True\n",
    "                                )\n",
    "        blr.fit(X_train_preprocessed[:num_samples,subset], y_train_cleaned[:num_samples])\n",
    "        if blr.log_model_evidence > highest_evidence:\n",
    "            highest_evidence = blr.log_model_evidence\n",
    "            best_subset = subset\n",
    "        \n",
    "        all_subsets.append(subset)\n",
    "        all_evidences.append(blr.log_model_evidence)\n",
    "        \n",
    "        print(\"Finished calculating evidence for subset number:\", i+1)\n",
    "\n",
    "    return highest_evidence, best_subset, all_evidences, all_subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation class\n",
    " This class is used to evaluate performance on a particular dataset, and takes in a fitted model. For example, evaluating performance on validation or test set and takes in fitted model on training set. It calculates all sorts of regression metrics and plots, comprehensively evaluating performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes used to evaluate fitted regressors using a range of evaluation metrics.\n",
    "class RegressionEvaluator(ABC):\n",
    "    def __init__(self, model, X_evaluation_preprocessed, y_evaluation_cleaned, feature_names):\n",
    "        self.model = model\n",
    "        self.feature_names = feature_names\n",
    "        self.real = y_evaluation_cleaned \n",
    "        self.preds = self.model.predict(X_evaluation_preprocessed[:, :])\n",
    "\n",
    "    @abstractmethod\n",
    "    def plot_coefficients(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_coefficient_statistics(self):\n",
    "        pass\n",
    "    \n",
    "    def get_metrics(self):\n",
    "        mse = mean_squared_error(self.real, self.preds)\n",
    "        mae = mean_absolute_error(self.real, self.preds)\n",
    "        r2_coefficient = r2_score(self.real, self.preds)\n",
    "        return {\n",
    "            'mse': mse,\n",
    "            'mae': mae,\n",
    "            'r2_coefficient': r2_coefficient\n",
    "            }\n",
    "\n",
    "            \n",
    "    def plot_regression_plot(self):\n",
    "        sns.regplot(x = self.real, y = self.preds, color='blue', scatter_kws={'alpha': 0.5}, line_kws={'color': 'maroon'})\n",
    "        plt.plot([self.real.min(), self.real.max()], [self.real.min(), self.real.max()], 'k--', lw=2)\n",
    "        plt.title('True Values against Predicted Values')\n",
    "        plt.xlabel('True values', fontsize=14)\n",
    "        plt.ylabel('Predicted values', fontsize=14)\n",
    "\n",
    "        legend_elements = [\n",
    "            Line2D([0], [0], marker='o', color='w', label='Data', markerfacecolor='blue', markersize=8, alpha=0.5),\n",
    "            Line2D([0], [0], color='maroon', lw=2, label='Regression Line'),\n",
    "            Line2D([0], [0], color='k', lw=2, linestyle='--', label='45° Line (Ideal)')\n",
    "        ]\n",
    "\n",
    "        plt.legend(handles = legend_elements)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_residual_plot(self):\n",
    "        residuals = self.real - self.preds\n",
    "        sns.residplot(x=self.preds, y=residuals, color='blue', scatter_kws={'alpha':0.5})\n",
    "        plt.title('Residuals Plot')\n",
    "        plt.xlabel('Predicted values', fontsize=14)\n",
    "        plt.ylabel('Residuals', fontsize=14)\n",
    "        plt.show()\n",
    "\n",
    "    def get_all_regression_metrics(self):\n",
    "        metrics = self.get_metrics()\n",
    "        print(metrics)\n",
    "        self.plot_coefficients()\n",
    "        self.plot_regression_plot()\n",
    "        self.plot_residual_plot()\n",
    "        self.get_coefficient_statistics()\n",
    "\n",
    "        \n",
    "class BayesianLinearRegressionEvaluator(RegressionEvaluator):\n",
    "    def __init__(self, model, X_evaluation_preprocessed, y_evaluation_cleaned, feature_names):\n",
    "        super().__init__(model, X_evaluation_preprocessed, y_evaluation_cleaned, feature_names)\n",
    "        \n",
    "    def plot_coefficients(self):\n",
    "        coefficients = self.model.coef_\n",
    "        self.feature_names = pd.Index(['intercept']).append(self.feature_names)\n",
    "        plt.bar(range(len(self.feature_names)), np.abs(coefficients))\n",
    "        plt.xticks(range(len(self.feature_names)),self.feature_names[:len(self.feature_names)],rotation=-45)\n",
    "        plt.xlabel('Coefficient')\n",
    "        plt.ylabel('Absolute value - log scale')\n",
    "        plt.yscale('log')\n",
    "        plt.show()\n",
    "    \n",
    "    def get_coefficient_statistics(self):\n",
    "        pd.set_option('display.width', None)\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        print(self.model.get_summary().to_string())\n",
    "        print()\n",
    "        \n",
    "\n",
    "class LinearRegressionEvaluator(RegressionEvaluator):\n",
    "    def __init__(self, model, X_evaluation_preprocessed, y_evaluation_cleaned, feature_names, stats_model):\n",
    "        self.stats_model = stats_model\n",
    "        super().__init__(model, X_evaluation_preprocessed, y_evaluation_cleaned, feature_names)\n",
    "        \n",
    "    def plot_coefficients(self):\n",
    "        coefficients = self.model.coef_\n",
    "        plt.bar(range(len(self.feature_names)), np.abs(coefficients))\n",
    "        plt.xticks(range(len(self.feature_names)),self.feature_names[:len(self.feature_names)],rotation=-45)\n",
    "        plt.xlabel('Coefficient')\n",
    "        plt.ylabel('Absolute value - log scale')\n",
    "        plt.yscale('log')\n",
    "        plt.show()\n",
    "        \n",
    "    def get_coefficient_statistics(self):\n",
    "        results = self.stats_model.fit()\n",
    "        print(results.summary())\n",
    "        print()\n",
    "    \n",
    "class GaussianProcessRegressionEvaluator(RegressionEvaluator):\n",
    "    def __init__(self, model, X_evaluation_preprocessed, y_evaluation_cleaned, feature_names):\n",
    "        super().__init__(model, X_evaluation_preprocessed, y_evaluation_cleaned, feature_names)\n",
    "        \n",
    "    def _plot_coefficient_plotter(self, importance):\n",
    "        plt.bar(range(len(self.feature_names)), np.abs(importance))\n",
    "        plt.xticks(range(len(self.feature_names)),self.feature_names[:len(self.feature_names)],rotation=-45)\n",
    "        plt.title(\"GP Feature Importance (1 / Length Scale)\")\n",
    "        plt.xlabel('Coefficient')\n",
    "        plt.ylabel('Feature Importance (log scale)')\n",
    "        plt.yscale('log')\n",
    "        plt.show()\n",
    "        \n",
    "    def get_coefficient_statistics(self):\n",
    "        return super().get_coefficient_statistics()\n",
    "    \n",
    "    def plot_coefficients(self):\n",
    "        kernel_params = self.model.kernel_.get_params()\n",
    "        length_scale_params = []\n",
    "        for kp_key in kernel_params:\n",
    "            if kp_key.endswith(\"length_scale\"):\n",
    "                length_scale_params.append(kp_key)\n",
    "        \n",
    "        for i in range(len(length_scale_params)):\n",
    "            coefficients = kernel_params[length_scale_params[i]]\n",
    "            if isinstance(coefficients, np.float64):\n",
    "                print(\"Isotropic kernel with length_scale value:\", coefficients)\n",
    "                continue\n",
    "            importance = 1 / coefficients\n",
    "            self._plot_coefficient_plotter(importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Process Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Process Regression using 1 covariate: Plotting the fit\n",
    "\n",
    "Here, we are training a basic Gaussian Process regression model using quadratic exponential kernel on just 1 covariate (carat). We do this so we can visually see how Gaussian Process Regression actually works.\n",
    "This section serves as a foundation for later more complex Gaussian Process models, which will utilize all covariates. We will not be able to visualize the fits of the regression in those cases.\n",
    "We will also plot 95% confidence intervals across the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = ConstantKernel(constant_value=1,constant_value_bounds=(1e+1, 1e+10)) * RBF(length_scale=1.0, length_scale_bounds=(1e-5, 100)) + WhiteKernel(noise_level=1 ** 2, noise_level_bounds=(1e-5, 1e+10))\n",
    "gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n",
    "\n",
    "\n",
    "X_train_preprocessed_1500, _, y_train_cleaned_1500, _ = random_subsampling_split(X_train_preprocessed, y_train_cleaned, tr_size = 1500)\n",
    "gp.fit(X_train_preprocessed_1500[:, -3:-2], y_train_cleaned_1500)\n",
    "gp.kernel_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the val set\n",
    "y_preds_val_set, sigma_preds_val_set= gp.predict(\n",
    "    X_val_preprocessed[:, -3:-2], \n",
    "    return_std=True\n",
    "    )\n",
    "\n",
    "# For all values in a linear space, best option for plotting.\n",
    "X_linspace = np.expand_dims(np.linspace(-10, 10, 10000), 1)\n",
    "y_preds_linspace, sigma_preds_linspace= gp.predict(\n",
    "    X_linspace, \n",
    "    return_std=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_preds_val_set, y_val_cleaned)\n",
    "mae = mean_absolute_error(y_preds_val_set, y_val_cleaned)\n",
    "r2 = r2_score(y_preds_val_set, y_val_cleaned)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"R2 coefficient\", r2)\n",
    "\n",
    "plt.plot(X_train_preprocessed_1500[:, -3], y_train_cleaned_1500, 'o', label = 'Data')\n",
    "plt.plot(X_val_preprocessed[:, -3], y_val_cleaned, 'yo', label='Validation Observations')\n",
    "plt.plot(X_linspace, y_preds_linspace)\n",
    "plt.fill(\n",
    "    np.concatenate([X_linspace, X_linspace[::-1]]),\n",
    "    np.concatenate(\n",
    "        [y_preds_linspace - 1.9600 * sigma_preds_linspace,\n",
    "        (y_preds_linspace + 1.9600 * sigma_preds_linspace)[::-1]]),\n",
    "    alpha=.5, fc='b', ec='None', label='95% prediction interval'\n",
    ")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation to find best Gaussian Process Kernel\n",
    "\n",
    "Here we will do cross-validation via subsampling within the training set to find the best Gaussian Process model. The Gaussian Process model is fitted on all covariates. We then take the model with the lowest average MSE across all splits (10 splits). The reason we do the subsampling approach instead of k-fold approach is because Gaussian Process models are prohibited by the number of data points due to the algorithm's computational time complexity. We sample 1500 points from the training split, and then validate on unseen validation split in each fold.\n",
    "\n",
    "NOTE: I tried many more models, but to save time and space have presented results of only 2 models. The best results were achieved by the isotropic RBF kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Below cell took ~20 mins to run on Apple MacBook M1 Air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = ConstantKernel(constant_value=1,constant_value_bounds=(1e+1, 1e+10)) * RBF(length_scale=1.0, length_scale_bounds=(1e-5, 100)) + WhiteKernel(noise_level=1 ** 2, noise_level_bounds=(1e-5, 1e+10))\n",
    "gp_rbf = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n",
    "\n",
    "cv_scores_gp_rbf_all_cols = random_subsampling_cv(full_pipeline, X_train_cleaned, y_train_cleaned, mean_squared_error, gp_rbf, train_size = 1500, numeric_cols_only=False)\n",
    "print(cv_scores_gp_rbf_all_cols)\n",
    "print(np.mean(cv_scores_gp_rbf_all_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Below cell took ~40 mins to run on Apple MacBook M1 Air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = ConstantKernel(constant_value=1,constant_value_bounds=(1e+1, 1e+10)) * RationalQuadratic(length_scale=1.0, alpha=1.0) + WhiteKernel(noise_level=1 ** 2, noise_level_bounds=(1e-5, 1e+10))\n",
    "gp_rq = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n",
    "\n",
    "cv_scores_gp_rq_all_cols = random_subsampling_cv(full_pipeline, X_train_cleaned, y_train_cleaned, mean_squared_error, gp_rq, train_size = 1500, numeric_cols_only=False)\n",
    "print(cv_scores_gp_rq_all_cols)\n",
    "print(np.mean(cv_scores_gp_rq_all_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refitting best Gaussian Process model on entire training set and seeing performance on Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Refitting Gaussian on entire training set and evaluating fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = ConstantKernel(constant_value=1,constant_value_bounds=(1e+1, 1e+10)) * RBF(length_scale=1.0, length_scale_bounds=(1e-5, 1e+5)) + WhiteKernel(noise_level=1 ** 2, noise_level_bounds=(1e-5, 1e+10))\n",
    "\n",
    "gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n",
    "X_train_preprocessed_1500, _, y_train_cleaned_1500, _ = random_subsampling_split(X_train_preprocessed, y_train_cleaned, tr_size = 1500)\n",
    "gp.fit(X_train_preprocessed_1500[:, :], y_train_cleaned_1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.kernel_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_evaluator_gp = GaussianProcessRegressionEvaluator(model=gp, X_evaluation_preprocessed=X_val_preprocessed, y_evaluation_cleaned=y_val_cleaned, feature_names = X_train_cleaned.columns)\n",
    "regression_evaluator_gp.get_all_regression_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation\n",
    "In Standard Linear Regression, we aren't tuning any hyperparameters apart from choosing the amount of covariates. Removing any single covariate resulted in a loss of performance according to MSE. In addition, all coefficients are statistically significant according to t-tests conducted by the statsmodel package (this is done as part of the evaluator class).\n",
    "\n",
    "I have shown the cross-validation results below of the model with all covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores_lr_all_cols = k_fold_cross_validation(full_pipeline, X_train_cleaned, y_train_cleaned, 'neg_mean_squared_error', LinearRegression(), numeric_cols_only=False, n_splits=10)\n",
    "print(cv_scores_lr_all_cols)\n",
    "print(np.mean(cv_scores_lr_all_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refitting Linear Regression model on entire training set and seeing performance on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(fit_intercept=True)\n",
    "lr.fit(X_train_preprocessed[:, :], y_train_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_evaluator_lr = LinearRegressionEvaluator(model=lr, \n",
    "                                                    X_evaluation_preprocessed=X_val_preprocessed, \n",
    "                                                    y_evaluation_cleaned=y_val_cleaned, \n",
    "                                                    feature_names = X_train_cleaned.columns,\n",
    "                                                    stats_model=sm.OLS(y_val_cleaned, sm.add_constant(X_val_preprocessed[:, :])))\n",
    "regression_evaluator_lr.get_all_regression_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Linear Regression\n",
    "\n",
    "The following class implements Bayesian Linear Regression using a unit information prior and exposes a class interface similar to sklearn's implementation of regressors. It inherits from the base regressor class part of the sklearn package. It extends from it as after fitting, it is able to provide a pandas dataframe of the summary of the fitted model including coefficients and 95% confidence intervals for parameter estimates. This 95% confidence interval is constructed from both Monte-Carlo method and using a t-distribution allowing me to compare. It also automatically calculates model evidence after fitting to data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianLinearRegression(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, omega_0 = [[1.0]], mu_0 = [0], a_0 = 0.01, b_0 = 0.01, fit_intercept = True, unit_information_prior = True):\n",
    "        self.omega_0 = omega_0 \n",
    "        self.omega_0_inv = sc.linalg.inv(self.omega_0)\n",
    "        self.mu_0 = mu_0\n",
    "        self.a_0 = a_0\n",
    "        self.b_0 = b_0\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.unit_information_prior = unit_information_prior\n",
    "\n",
    "        \n",
    "    def _calculate_posteriors(self, X, y):\n",
    "        if self.fit_intercept:\n",
    "            X = np.column_stack([np.ones(X.shape[0]), X])\n",
    "        \n",
    "        XtX = X.T @ X\n",
    "        n, p = X.shape\n",
    "\n",
    "        if self.unit_information_prior:\n",
    "            self.omega_0 = n * sc.linalg.inv(X.T @ X)\n",
    "            self.omega_0_inv = sc.linalg.inv(self.omega_0)\n",
    "        \n",
    "        self.omega_n = sc.linalg.inv(XtX + self.omega_0_inv)\n",
    "        self.mu_n = self.omega_n @ (self.omega_0_inv @ self.mu_0 + X.T @ y)\n",
    "        self.a_n = self.a_0 + n/2\n",
    "        \n",
    "        term2 = y.T @ y + self.mu_0.T @ self.omega_0_inv @ self.mu_0 + self.mu_n.T @ sc.linalg.inv(self.omega_n) @ self.mu_n\n",
    "        self.b_n = self.b_0 + term2/2\n",
    "\n",
    "    def _get_marginal_t_distribution(self, mu, Sigma, j, nu):\n",
    "        sigma_j2 = Sigma[j, j]\n",
    "        return t(df = nu, loc=mu[j], scale = np.sqrt(sigma_j2))\n",
    "    \n",
    "    # y ~ N(XB, sigma^2 * I_n)\n",
    "    # p(y|B, sigma^2, X)\n",
    "    def __calculate_log_likelihood(self, X, y):\n",
    "        n, p = X.shape\n",
    "        # The variance of the residuals is distributed according to inverse gamma distribution\n",
    "        # The posterior params are a_n, b_n\n",
    "        sigma2 = self.b_n / (self.a_n - 1) # The mean of inverse gamma with params a, b is b / (a - 1)\n",
    "        cov = sigma2 * np.eye(n)\n",
    "        beta = self.mu_n\n",
    "        mu = X @ beta\n",
    "        log_likelihood = multivariate_normal.logpdf(y,mu,cov) # Note this line will struggle to when n > 10,000 due to 10,000x10,000 covariance matrix\n",
    "        return log_likelihood\n",
    "    \n",
    "    def __calculate_log_prior(self):\n",
    "        sigma2 = self.b_n / (self.a_n - 1)\n",
    "        beta = self.mu_n\n",
    "        log_prior = self.a_0 * np.log(self.b_0) - loggamma(self.a_0) - (self.a_0 + 1) * np.log(sigma2) - self.b_0 / sigma2\n",
    "        log_prior = log_prior + multivariate_normal.logpdf(beta,self.mu_0,sigma2*self.omega_0)\n",
    "        return log_prior\n",
    "    \n",
    "    def __calculate_log_posterior(self):\n",
    "        sigma2 = self.b_n / (self.a_n - 1)\n",
    "        beta = self.mu_n\n",
    "        log_posterior = self.a_n * np.log(self.b_n) - loggamma(self.a_n) - (self.a_n + 1) * np.log(sigma2) - self.b_n / sigma2\n",
    "        log_posterior = log_posterior + multivariate_normal.logpdf(beta,self.mu_n,sigma2*self.omega_n)\n",
    "        return log_posterior\n",
    "         \n",
    "    def _calculate_model_evidence(self, X, y):\n",
    "        if self.fit_intercept:\n",
    "            X = np.column_stack([np.ones(X.shape[0]), X])\n",
    "        log_likelihood = self.__calculate_log_likelihood(X, y)\n",
    "        log_prior = self.__calculate_log_prior()\n",
    "        log_posterior = self.__calculate_log_posterior()\n",
    "        log_model_evidence = log_likelihood + log_prior - log_posterior\n",
    "        return log_model_evidence   \n",
    "    \n",
    "    \n",
    "    def get_summary(self):\n",
    "        check_is_fitted(self)\n",
    "        \n",
    "        scale = (self.b_n / self.a_n) * self.omega_n\n",
    "        lower5_t = []\n",
    "        upper5_t = []\n",
    "        for i in range(0, len(scale)):\n",
    "            marginal = self._get_marginal_t_distribution(self.mu_n, scale, i, 2 * self.a_n)\n",
    "            lower, upper = marginal.ppf([0.025, 0.975])\n",
    "            lower5_t.append(lower)\n",
    "            upper5_t.append(upper)\n",
    "        lower5_t = np.array(lower5_t)\n",
    "        upper5_t = np.array(upper5_t)\n",
    "\n",
    "        np.random.seed(1)\n",
    "        betas = multivariate_t.rvs(loc = self.mu_n, shape=scale, df=2 * self.a_n, size=10000000)\n",
    "        lower5_sampling = np.percentile(betas, 2.5, axis=0)\n",
    "        upper5_sampling = np.percentile(betas, 97.5, axis=0)\n",
    "        results = np.column_stack([self.mu_n, lower5_sampling, upper5_sampling, lower5_t, upper5_t])\n",
    "        summary = pd.DataFrame(results, columns=['posterior mean','lower 95% bound (Monte Carlo Sampling)',\n",
    "                                                 'upper 95% bound (Monte Carlo Sampling)',\n",
    "                                                 'lower 95% bound (t-dist value)',\n",
    "                                                 'upper 95% bound (t-dist value)'], \n",
    "                               index=[f'x{j+1}' for j in range(len(scale))])\n",
    "        return summary\n",
    "        \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y)\n",
    "            \n",
    "        self._calculate_posteriors(X, y)\n",
    "        self.coef_ = self.mu_n\n",
    "        self.log_model_evidence = self._calculate_model_evidence(X, y)\n",
    "        return self\n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self)\n",
    "        X = check_array(X)\n",
    "        if self.fit_intercept:\n",
    "            X = np.column_stack([np.ones(X.shape[0]), X])\n",
    "        return X @ self.mu_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian Model Evidence\n",
    "For the Bayesian Linear Regression model, I decided to choose the number of covariates according to the highest marginal likelihood. I used the unit information prior with mean 0. This way we automatically choose a model while optimizing parsimony as opposed to optimizing predictive power, and seeing if this approach is able to significantly reduce the error on the validation set using this alternative approach.\n",
    "\n",
    "One thing to note is calculating the likelihood is computationally extremely difficult when $n \\geq 10000$ (The covariance matrix is of this dimension), and this is necessary to calculate the marginal likelihood. Hence we are limited to training on a subset of the training dataset of size 10,000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: The below cell took 30 mins to run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_evidence, best_feature_subset, all_evidences, all_feature_subsets = bayesian_model_evidence_selection(full_pipeline, \n",
    "                                                                            X_train_cleaned, \n",
    "                                                                            y_train_cleaned, \n",
    "                                                                            BayesianLinearRegression,\n",
    "                                                                            num_samples=10000,\n",
    "                                                                            num_models=10,\n",
    "                                                                            )\n",
    "\n",
    "print(\"Best Model Evidence:\", best_evidence)\n",
    "print(\"Best Feature Subset:\", best_feature_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_evidences)\n",
    "print(all_feature_subsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refitting model with highest marginal likelihood on the training set and evaluating performance on validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blr = BayesianLinearRegression(\n",
    "                               mu_0=np.zeros(len(best_feature_subset)+1),\n",
    "                               a_0=0.01,\n",
    "                               b_0=0.01,\n",
    "                               fit_intercept=True,\n",
    "                               unit_information_prior=True\n",
    "                               )\n",
    "\n",
    "num_samples_blr = 10000\n",
    "blr.fit(X_train_preprocessed[:num_samples_blr,best_feature_subset], y_train_cleaned[:num_samples_blr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_evaluator_blr = BayesianLinearRegressionEvaluator(model=blr, \n",
    "                                                    X_evaluation_preprocessed=X_val_preprocessed[:, best_feature_subset], \n",
    "                                                    y_evaluation_cleaned=y_val_cleaned, \n",
    "                                                    feature_names = X_train_cleaned.columns[best_feature_subset],\n",
    "                                                    )\n",
    "regression_evaluator_blr.get_all_regression_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model we found was the isotropic Gaussian Process Regressor. This gave a validation MSE of around 540,000. The error on the test set is lower than the validation, of around 510,000. This model marks a signicant improvement compared to Linear Regression and Bayesian Linear Regression models, highlighting the non-linear structure of the underlying data. This has successfully been captured by a Gaussian Process Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_evaluator_gp_test_set = GaussianProcessRegressionEvaluator(model=gp, X_evaluation_preprocessed=X_test_preprocessed, y_evaluation_cleaned=y_test_cleaned, feature_names = X_train_cleaned.columns)\n",
    "regression_evaluator_gp_test_set.get_all_regression_metrics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
